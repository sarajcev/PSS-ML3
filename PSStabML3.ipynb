{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manifold learning in Power System Transient Stability Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.manifold import Isomap, TSNE, MDS\n",
    "from sklearn.manifold import SpectralEmbedding as SE\n",
    "from sklearn.manifold import LocallyLinearEmbedding as LLE\n",
    "from sklearn.decomposition import PCA, KernelPCA, TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure aesthetics\n",
    "sns.set(context='paper', style='white', font_scale=1.1)\n",
    "sns.set_style('ticks', {'xtick.direction':'in', 'ytick.direction':'in'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power System Transient Stability Analysis Data (IEEE Benchmark Test Case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('GridDictionary2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Percentage of \"ones\" in the \"Stability\" column.\n",
    "print('There is {:.1f}% of unstable cases in the dataset!'\n",
    "      .format(data['Stability'].sum()/float(len(data['Stability']))*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_features = len(data.columns) - 1\n",
    "X_data = data.iloc[:, 0:no_features]  # features\n",
    "print('X_data', X_data.shape)\n",
    "y_data = data['Stability']\n",
    "print('y_data', y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratify shuffle split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_data, y_data, train_size=0.8, stratify=y_data, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('X_train', X_train.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('X_test', X_test.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Unstable cases in training dataset: {:.1f}%:'\n",
    "      .format(np.sum(y_train)/float(len(y_train))*100.))\n",
    "print('Unstable cases in testing dataset {:.1f}%:'\n",
    "      .format(np.sum(y_test)/float(len(y_test))*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stable cases index values.\n",
    "idx_stable = y_test==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring models using cross-validated metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_default(X, y):\n",
    "    \"\"\" Scoring default SVC model. \"\"\"\n",
    "    # Score with default hyperparameters.\n",
    "    scores = cross_val_score(svm.SVC(kernel='rbf', class_weight='balanced'), \n",
    "                             X, y, cv=3, scoring='f1')\n",
    "    print('Score using 3-fold CV: {:g} +/- {:g}'\n",
    "          .format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_optimized(X, y, C, gamma):\n",
    "    \"\"\" Scoring optimized SVC model. \"\"\"\n",
    "    # Score with the optimized hyperparameters.\n",
    "    scores = cross_val_score(svm.SVC(C=C, gamma=gamma, kernel='rbf', \n",
    "                                     class_weight='balanced'), \n",
    "                             X, y, cv=3, scoring='f1', n_jobs=-1)\n",
    "    print('Score using 3-fold CV: {:g} +/- {:g}'\n",
    "          .format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_projection(X, idx):\n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    ax.scatter(X[idx,0], X[idx,1], \n",
    "            s=20, c='green', marker='o', edgecolors='k', alpha=0.5, label='Stable')\n",
    "    ax.scatter(X[~idx,0], X[~idx,1], \n",
    "            s=20, c='red', marker='o', edgecolors='k', alpha=0.5, label='Unstable')\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_xlabel('First component')\n",
    "    ax.set_ylabel('Second component')\n",
    "    ax.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the input data.\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Following dimmensionality reduction methods are examined:\n",
    "\n",
    "* **PCA** (principal components analysis)\n",
    "* **kPCA** (kernelized principal components analysis)\n",
    "* **tSVD** (truncated singular value decomposition)\n",
    "* **iMAP** (isomap embedding)\n",
    "* **t-SNE** (T-distributed stochastic neighbor embedding)\n",
    "* **LLE** (locally linear embedding)\n",
    "* **LLE:LTSA** (locally linear embedding with local tangent space alignment algorithm)\n",
    "* **LLE:H** (locally linear embedding with Hessian eigenmap method)\n",
    "* **SE** (spectral embedding)\n",
    "* **MDS** (multi-dimensional scaling)\n",
    "\n",
    "Some of these have their own hyperparameters (e.g. KernelPCA) which can be optimized together with the hyperparameters of the SVC estimator. This will be shown for the KernelPCA method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization with simulated annealing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulated annealing is used for optimizing hyperparameters of the SVC estimator only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_cv(C, gamma, X_data, y_data):\n",
    "    \"\"\" \n",
    "    SVC cross validation.\n",
    "    \n",
    "    This function will instantiate a SVC classifier with a \n",
    "    RBF kernel and hyper-parameters C and gamma. Combined\n",
    "    with data and targets it will be used to perform cross\n",
    "    validation. The goal is to find combinations of C and\n",
    "    gamma that maximizes the `f1` scoring metric.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    C: float\n",
    "        Regularization parameter (penalty is a squared l2). \n",
    "    gamma: float\n",
    "        Kernel coefficient.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cval: float\n",
    "        Mean value of the score from the cross-validation.\n",
    "    \"\"\"\n",
    "    # Instantiate SVC with RBF kernel and class weight balancing.\n",
    "    estimator = svm.SVC(C=C, gamma=gamma, kernel='rbf', \n",
    "                        class_weight='balanced', probability=True)\n",
    "    # Score the estimator using cross validation.\n",
    "    cval = cross_val_score(estimator, X_data, y_data, \n",
    "                           scoring='f1', cv=2, n_jobs=-1)\n",
    "    \n",
    "    return -cval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_svc(X_data, y_data, x0, coolC=10., sigma=1., burn=10, eps=1e-6):\n",
    "    \"\"\" \n",
    "    Apply Simulated Annealing to optimize SVC hyperparameters.\n",
    "    \"\"\"\n",
    "    from annealing import simulated_annealing\n",
    "\n",
    "    def svc_crossval(expC, expGamma):\n",
    "        \"\"\" \n",
    "        Wrapper for the SVC cross-validation function.\n",
    "        \"\"\"\n",
    "        # Exploring parameters in 'log' space.\n",
    "        C = 10**expC\n",
    "        gamma = 10**expGamma\n",
    "        model_instance = svc_cv(C, gamma, X_data, y_data)\n",
    "        \n",
    "        return model_instance\n",
    "\n",
    "    # Simulated Annealing.\n",
    "    x, E = simulated_annealing(svc_crossval, x0, \n",
    "                               C=coolC, sigma=sigma, burn=burn, eps=eps)\n",
    "    \n",
    "    return x, E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature schedule.\n",
    "x = np.arange(200)\n",
    "T0 = 1.\n",
    "y1 = T0*np.exp(-x/10)\n",
    "y2 = T0*np.exp(-x/50)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6.5,2.5))\n",
    "ax[0].plot(x, y1, lw=2, label=r'$\\zeta$ = 10')\n",
    "ax[0].plot(x, y2, lw=2, label=r'$\\zeta$ = 50')\n",
    "ax[0].set_xlabel('Iterations')\n",
    "ax[0].set_ylabel('Temperature')\n",
    "ax[0].legend(loc='upper right')\n",
    "ax[0].grid()\n",
    "ax[1].semilogy(x, y1, lw=2, label=r'$\\zeta$ = 10')\n",
    "ax[1].semilogy(x, y2, lw=2, label=r'$\\zeta$ = 50')\n",
    "ax[1].set_xlabel('Iterations')\n",
    "ax[1].set_ylabel('Temperature')\n",
    "ax[1].legend(loc='lower left')\n",
    "ax[1].grid(which='both')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial values (C, gamma).\n",
    "x0 = np.array([1., -1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal components analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `whiten` to True/False to see if there is any difference.\n",
    "pca = PCA(n_components=2, whiten=True).fit(X_train)\n",
    "X_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explained variance\n",
    "np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_projection(X_pca, idx_stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_default(X_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize SVC hyperparameters using simulated annealing.\n",
    "x, E = optimize_svc(X_pca, y_test, x0, burn=10, eps=1e-8)\n",
    "print(x, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10**x[0]\n",
    "gamma = 10**x[1]\n",
    "score_optimized(X_pca, y_test, C, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction using KernelPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulated annealing is here used for optimizing the hyperparameters of the KernelPCA and the SVC estimator at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpca_svc_cv(C, gamma, gamma_kpca, X_data, y_data):\n",
    "    \"\"\" SVC cross validation with KernelPCA. \"\"\"\n",
    "    # Instantiate SVC with RBF kernel and class weight balancing.\n",
    "    estimator = svm.SVC(C=C, gamma=gamma, kernel='rbf', \n",
    "                        class_weight='balanced', probability=True)\n",
    "    reduction = KernelPCA(n_components=2, kernel='rbf', gamma=gamma_kpca)\n",
    "    pipe = Pipeline([\n",
    "        ('kpca', reduction),\n",
    "        ('svm', estimator)\n",
    "    ])\n",
    "    # Score the estimator using cross validation.\n",
    "    cval = cross_val_score(pipe, X_data, y_data, \n",
    "                           scoring='f1', cv=2, n_jobs=-1)\n",
    "    \n",
    "    return -cval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_kpca_svc(X_data, y_data, x0, \n",
    "                      coolC=10., sigma=1., burn=10, eps=1e-6):\n",
    "    \"\"\" \n",
    "    Apply Simulated Annealing to optimize SVC & kPCA hyperparameters.\n",
    "    \"\"\"\n",
    "    from annealing import simulated_annealing\n",
    "\n",
    "    def kpca_svc_crossval(expC, expGamma, expGammkPCA):\n",
    "        \"\"\" \n",
    "        Wrapper for the SVC cross-validation function.\n",
    "        \"\"\"\n",
    "        # Exploring parameters in 'log' space.\n",
    "        C = 10**expC\n",
    "        gamma = 10**expGamma\n",
    "        gamma_kpca = 10**expGammkPCA\n",
    "        model_instance = kpca_svc_cv(C, gamma, gamma_kpca, X_data, y_data)\n",
    "        \n",
    "        return model_instance\n",
    "\n",
    "    # Simulated Annealing.\n",
    "    x, E = simulated_annealing(kpca_svc_crossval, x0, \n",
    "                               C=coolC, sigma=sigma, burn=burn, eps=eps)\n",
    "    \n",
    "    return x, E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial values (C-SVM, Gamma-SVM, Gamma-kPCA)\n",
    "xk0 = np.array([1., -1., -1.])\n",
    "# Optimize kPCA & SVC hyperparameters using simulated annealing.\n",
    "x, E = optimize_kpca_svc(X_train, y_train, xk0, burn=10, eps=1e-8)\n",
    "print(x, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca_opt = KernelPCA(n_components=2, kernel='rbf', \n",
    "                     gamma=10**x[2], # optimal value\n",
    "                     n_jobs=-1).fit(X_train)\n",
    "X_kpca_opt = kpca_opt.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_projection(X_kpca_opt, idx_stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_default(X_kpca_opt, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10**x[0]\n",
    "gamma = 10**x[1]\n",
    "score_optimized(X_kpca_opt, y_test, C, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KernelPCA without the kPCA kernel optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce features in the dataset down to only 2 principal components.\n",
    "kpca = KernelPCA(n_components=2, kernel='rbf', n_jobs=-1).fit(X_train)\n",
    "X_kpca = kpca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_projection(X_kpca, idx_stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_default(X_kpca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize SVC hyperparameters using simulated annealing.\n",
    "x, E = optimize_svc(X_kpca, y_test, x0, burn=10, eps=1e-8)\n",
    "print(x, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10**x[0]\n",
    "gamma = 10**x[1]\n",
    "score_optimized(X_kpca, y_test, C, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction using truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=2).fit(X_train)\n",
    "X_svd = svd.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_projection(X_svd, idx_stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_default(X_svd, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize SVC hyperparameters using simulated annealing.\n",
    "x, E = optimize_svc(X_svd, y_test, x0, burn=10, eps=1e-8)\n",
    "print(x, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10**x[0]\n",
    "gamma = 10**x[1]\n",
    "score_optimized(X_svd, y_test, C, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isomap embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso = Isomap(n_components=2, n_neighbors=50, n_jobs=-1).fit(X_train)\n",
    "X_iso = iso.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_projection(X_iso, idx_stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_default(X_iso, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize SVC hyperparameters using simulated annealing.\n",
    "x, E = optimize_svc(X_iso, y_test, x0, burn=10, eps=1e-8)\n",
    "print(x, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10**x[0]\n",
    "gamma = 10**x[1]\n",
    "score_optimized(X_iso, y_test, C, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-distributed Stochastic Neighbor Embedding (t-SNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-SNE with optimized hyperparameters\n",
    "\n",
    "Here hyperparameters of the t-SNE (`perplexity` and `early_exaggeration`) are optimized together with the hyperparameters of the underlying SVC estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_svc_cv(C, gamma, perplex, X_data, y_data):\n",
    "    \"\"\" SVC cross validation with t-SNE. \"\"\"\n",
    "    # Instantiate SVC with RBF kernel and class weight balancing.\n",
    "    estimator = svm.SVC(C=C, gamma=gamma, kernel='rbf', \n",
    "                        class_weight='balanced', probability=True)\n",
    "    reduction = TSNE(n_components=2, perplexity=perplex)\n",
    "    pipe = Pipeline([\n",
    "        ('tsne', reduction),\n",
    "        ('svm', estimator)\n",
    "    ])\n",
    "    # Score the estimator using cross validation.\n",
    "    cval = cross_val_score(pipe, X_data, y_data, \n",
    "                           scoring='f1', cv=2, n_jobs=-1)\n",
    "    \n",
    "    return -cval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_tsne_svc(X_data, y_data, x0, \n",
    "                      coolC=10., sigma=1., burn=10, eps=1e-6, verbose=False):\n",
    "    \"\"\" \n",
    "    Apply Simulated Annealing to optimize t-SNE & kPCA hyperparameters.\n",
    "    \"\"\"\n",
    "    from annealing import simulated_annealing\n",
    "\n",
    "    def tsne_svc_crossval(expC, expGamma, expPerplex):\n",
    "        \"\"\" \n",
    "        Wrapper for the SVC cross-validation function.\n",
    "        \"\"\"\n",
    "        from numpy import exp\n",
    "\n",
    "        # Exploring parameters C, Gamma in common logarithm (log) space.\n",
    "        C = 10**expC\n",
    "        gamma = 10**expGamma\n",
    "        # Exploring parameter perplexity in natural logarithm (ln) space.\n",
    "        perplex = exp(expPerplex)\n",
    "        model_instance = kpca_svc_cv(C, gamma, perplex, X_data, y_data)\n",
    "        \n",
    "        return model_instance\n",
    "\n",
    "    # Simulated Annealing.\n",
    "    x, E = simulated_annealing(tsne_svc_crossval, x0, \n",
    "                               C=coolC, sigma=sigma, burn=burn, \n",
    "                               eps=eps, verbose=verbose)\n",
    "    \n",
    "    return x, E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial values (C, gamma, perplexity)\n",
    "xt0 = np.array([1., -1., 3.])\n",
    "# Optimize t-SNE & SVC hyperparameters using simulated annealing.\n",
    "x, E = optimize_tsne_svc(X_test, y_test, xt0, burn=10, eps=1e-8, verbose=True)\n",
    "print(x, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tsne_opt = TSNE(n_components=2, \n",
    "                  perplexity=np.exp(x[2]), # optimal value\n",
    "                  n_jobs=-1).fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_projection(X_tsne_opt, idx_stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_default(X_tsne_opt, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10**x[0]\n",
    "gamma = 10**x[1]\n",
    "score_optimized(X_tsne_opt, y_test, C, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-SNE without hyperparameters optimization\n",
    "\n",
    "Hyperparameters of the t-SNE are not being optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tsne = TSNE(n_components=2, n_jobs=-1).fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_projection(X_tsne, idx_stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_default(X_tsne, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize SVC hyperparameters using simulated annealing.\n",
    "x, E = optimize_svc(X_tsne, y_test, x0, burn=10, eps=1e-8)\n",
    "print(x, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10**x[0]\n",
    "gamma = 10**x[1]\n",
    "score_optimized(X_tsne, y_test, C, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locally Linear Embedding (LLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lle = LLE(n_components=2, n_neighbors=50, \n",
    "          method='standard', n_jobs=-1).fit(X_train)\n",
    "X_lle = lle.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_projection(X_lle, idx_stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_default(X_lle, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize SVC hyperparameters using simulated annealing.\n",
    "x, E = optimize_svc(X_lle, y_test, x0, burn=10, eps=1e-8)\n",
    "print(x, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10**x[0]\n",
    "gamma = 10**x[1]\n",
    "score_optimized(X_lle, y_test, C, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locally linear embedding with LTSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltsa = LLE(n_components=2, n_neighbors=50, \n",
    "           method='ltsa', eigen_solver='dense', n_jobs=-1).fit(X_train)\n",
    "X_ltsa = ltsa.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_projection(X_ltsa, idx_stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_default(X_ltsa, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize SVC hyperparameters using simulated annealing.\n",
    "x, E = optimize_svc(X_ltsa, y_test, x0, burn=10, eps=1e-8)\n",
    "print(x, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10**x[0]\n",
    "gamma = 10**x[1]\n",
    "score_optimized(X_ltsa, y_test, C, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locally linear embedding with Hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hess = LLE(n_components=2, n_neighbors=100, \n",
    "           method='hessian', n_jobs=-1).fit(X_train)\n",
    "X_hess = hess.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_projection(X_hess, idx_stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_default(X_hess, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize SVC hyperparameters using simulated annealing.\n",
    "x, E = optimize_svc(X_hess, y_test, x0, burn=10, eps=1e-8)\n",
    "print(x, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10**x[0]\n",
    "gamma = 10**x[1]\n",
    "score_optimized(X_hess, y_test, C, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified locally linear embedding (MLLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlle = LLE(n_components=2, n_neighbors=50, \n",
    "           method='modified', n_jobs=-1).fit(X_train)\n",
    "X_mlle = lle.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_projection(X_mlle, idx_stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_default(X_mlle, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize SVC hyperparameters using simulated annealing.\n",
    "x, E = optimize_svc(X_mlle, y_test, x0, burn=10, eps=1e-8)\n",
    "print(x, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10**x[0]\n",
    "gamma = 10**x[1]\n",
    "score_optimized(X_mlle, y_test, C, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_spec = SE(n_components=2, affinity='nearest_neighbors', \n",
    "            n_jobs=-1).fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_projection(X_spec, idx_stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_default(X_spec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize SVC hyperparameters using simulated annealing.\n",
    "x, E = optimize_svc(X_spec, y_test, x0, burn=25, eps=1e-8)\n",
    "print(x, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10**x[0]\n",
    "gamma = 10**x[1]\n",
    "score_optimized(X_spec, y_test, C, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-dimensional scaling (MDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mds = MDS(n_components=2, metric=True, n_jobs=-1).fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_projection(X_mds, idx_stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_default(X_mds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize SVC hyperparameters using simulated annealing.\n",
    "x, E = optimize_svc(X_mds, y_test, x0, burn=10, eps=1e-8)\n",
    "print(x, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10**x[0]\n",
    "gamma = 10**x[1]\n",
    "score_optimized(X_mds, y_test, C, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-Recall Tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use \"best\" SVC parameters here.\n",
    "best_parameters = {'C': C, 'gamma': gamma}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = cross_val_predict(svm.SVC(**best_parameters, probability=True, \n",
    "                                     class_weight='balanced'), \n",
    "                             X_test, y_test, cv=3, \n",
    "                             method='predict_proba',\n",
    "                             n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = y_probas[:,1]  # score == probability of positive class\n",
    "precisions, recalls, thresholds = metrics.precision_recall_curve(y_test, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4.5,4.5))\n",
    "ax.plot(precisions, recalls, lw=2, label='SVC')\n",
    "default = np.argmin(np.abs(thresholds - 0.5))\n",
    "ax.plot(precisions[default], recalls[default], '^', c='k', markersize=10, \n",
    "        label='Threshold = 0.5', fillstyle='none', mew=2)\n",
    "ax.set_xlabel('Precision')\n",
    "ax.set_ylabel('Recall')\n",
    "ax.legend(loc='best')\n",
    "ax.grid()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot decision region for test samples with only two features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Select projected data.\n",
    "X_test_best = X_mds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate SVC from selected projection.\n",
    "svc_best = svm.SVC(C=C, gamma=gamma, kernel='rbf', \n",
    "                   class_weight='balanced', probability=True).fit(X_test_best, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.1; delta = 0.01\n",
    "x_min, x_max = X_test_best[:,0].min() - h, X_test_best[:,0].max() + h\n",
    "y_min, y_max = X_test_best[:,1].min() - h, X_test_best[:,1].max() + h\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, delta), np.arange(y_min, y_max, delta))\n",
    "Z = svc_best.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,1]\n",
    "Z = Z.reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "ax.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu, alpha=0.8)\n",
    "ax.scatter(X_test_best[idx_stable,0], X_test_best[idx_stable,1], \n",
    "           s=30, c='green', marker='o', edgecolors='k', alpha=0.5, label='Stable')\n",
    "ax.scatter(X_test_best[~idx_stable,0], X_test_best[~idx_stable,1], \n",
    "           s=30, c='red', marker='o', edgecolors='k', alpha=0.5, label='Unstable')\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_xlabel('1st component')\n",
    "ax.set_ylabel('2nd component')\n",
    "ax.set_xlim(x_min, x_max)\n",
    "ax.set_ylim(y_min, y_max)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, IPython, sklearn, scipy, matplotlib\n",
    "print(\"Notebook createad with:\\\n",
    "      \\nPython {:s}\\nIPython {:s}\\nScikit-learn {:s}\\nPandas {:s}\\nNumpy \\\n",
    "      {:s}\\nScipy {:s}\\nMatplotlib {:s}\"\\\n",
    "      .format(sys.version[:5], IPython.__version__, sklearn.__version__, \n",
    "              pd.__version__, np.__version__, scipy.__version__, \n",
    "              matplotlib.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
